# Задание

Не ожидаем production-ready решения. Сделайте, как кажется правильным, опишите процесс поиска и принятые решения.

Опишите решение для веб-приложения в kubernetes в виде yaml-манифеста. Оставляйте в коде комментарии по принятым решениям. Есть следующие вводные:

1. У нас kubernetes кластер, в котором пять нод.
2. Приложение испытывает постоянную стабильную нагрузку в течение суток без значительных колебаний. 3 пода справляются с нагрузкой.
3. На первые запросы приложению требуется значительно больше ресурсов CPU, в дальнейшем потребление ровное в районе 0.1 CPU. По памяти всегда “ровно” в районе 128M memory.
4. Приложение требует около 5-10 секунд для инициализации.

Что хотим?

1. Минимальное потребление ресурсов от этого deployment’а.
2. Размещение подов на разных нодах для отказоустойчивости.
3. Чтобы под не обрабатывал запросы до завершения инициализации.

# Описание решения

## Ключевые решения:

### Ресурсные ограничения:

1. requests: Установили 0.2 CPU и 128Mi памяти. CPU немного завышено для старта, чтобы учесть высокие затраты на первые запросы.
2. limits: Ограничили ресурсы, чтобы поды не захватывали слишком много ресурсов CPU (0.5 CPU) и памяти (256Mi).
3. startupProbe и readinessProbe:
* startupProbe: Даем поду время для инициализации. Если приложение не успеет инициализироваться за отведённое время (3 неудачные проверки по 5 секунд), оно будет перезапущено.
* readinessProbe: Следит за тем, чтобы под не начал обрабатывать запросы, пока не будет готов. Указана задержка 10 секунд, что учитывает время на прогрев.

4. Affinity для отказоустойчивости:

### Важно!

* Добавил podAntiAffinity, чтобы каждый под находился на отдельной ноде.
* Следуя логике задания, по идее, здесь требуется *requiredDuringSchedulingIgnoredDuringExecution*.
* Но, я все же бы сделал *preferredDuringSchedulingIgnoredDuringExecution*. ДА, я осознаю, что у нас 5 нод, а пода всего 3. К сожалению, у нод зачастую есть привычка умирать. Если Кластеру в один момент не хватит нод для строгого размещения подов на них, то под просто не появится, пока нода не станет доступной. Я предполагаю, что лучше уж разместить в таком случаем 2 пода на одной ноде, чем вообще не поднимать под.

#### Дополнительные соображения:

#### Restart Policy — установлено значение Always, чтобы поды перезапускались при сбоях.

#### Также можно было бы добавить HPA для скейлинга в случае, если процессор вдруг начал кушать много ресурсов.

* minReplicas: 3  
* maxReplicas: 5 

С проверкой CPU utilization. averageUtilization:

#### Можно добавить логирование и мониторинг. Prometheus и т.д.

#### Update Strategy - добавить rollingUpdate для безостановочной работы приложения при обновлениях.